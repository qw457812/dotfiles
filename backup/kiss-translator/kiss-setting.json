{
  "darkMode": true,
  "uiLang": "zh",
  "minLength": 2,
  "maxLength": 100000,
  "newlineLength": 20,
  "httpTimeout": 10000,
  "clearCache": false,
  "injectRules": true,
  "fabClickAction": 0,
  "contextMenuType": 1,
  "subrulesList": [
    {
      "url": "https://fishjar.github.io/kiss-rules/kiss-rules_v2.json",
      "selected": true
    },
    {
      "url": "https://fishjar.github.io/kiss-rules/kiss-rules-on_v2.json",
      "selected": false
    },
    {
      "url": "https://fishjar.github.io/kiss-rules/kiss-rules-off_v2.json",
      "selected": false
    }
  ],
  "transApis": [
    {
      "apiSlug": "BuiltinAI",
      "apiName": "BuiltinAI",
      "apiType": "BuiltinAI",
      "url": "",
      "key": "",
      "model": "",
      "systemPrompt": "Act as a translation API. Output a single raw JSON object only. No extra text or fences.\n\nInput:\n{\"targetLanguage\":\"<lang>\",\"title\":\"<context>\",\"description\":\"<context>\",\"segments\":[{\"id\":1,\"text\":\"...\"}],\"glossary\":{\"sourceTerm\":\"targetTerm\"},\"tone\":\"<formal|casual>\"}\n\nOutput:\n{\"translations\":[{\"id\":1,\"text\":\"...\",\"sourceLanguage\":\"<detected>\"}]}\n\nRules:\n1.  Use title/description for context only; do not output them.\n2.  Keep id, order, and count of segments.\n3.  Preserve whitespace, HTML entities, and all HTML-like tags (e.g., <i1>, <a1>). Translate inner text only.\n4.  Highest priority: Follow 'glossary'. Use value for translation; if value is \"\", keep the key.\n5.  Do not translate: content in <code>, <pre>, text enclosed in backticks, or placeholders like {1}, {{1}}, [1], [[1]].\n6.  Apply the specified tone to the translation.\n7.  Detect sourceLanguage for each segment.\n8.  Return empty or unchanged inputs as is.\n\nExample:\nInput: {\"targetLanguage\":\"zh-CN\",\"segments\":[{\"id\":1,\"text\":\"A <b>React</b> component.\"}],\"glossary\":{\"component\":\"组件\",\"React\":\"\"}}\nOutput: {\"translations\":[{\"id\":1,\"text\":\"一个<b>React</b>组件\",\"sourceLanguage\":\"en\"}]}\n\nFail-safe: On any error, return {\"translations\":[]}.",
      "subtitlePrompt": "You are an expert AI for subtitle generation. Convert a JSON array of word-level timestamps into a bilingual VTT file.\n\n**Workflow:**\n1. Merge `text` fields into complete sentences; ignore empty text.\n2. Split long sentences into smaller, manageable subtitle cues (one sentence per cue).\n3. Translate each cue into {{to}}.\n4. Format as VTT:\n   - Start with `WEBVTT`.\n   - Each cue: timestamps (`start --> end` in milliseconds), original text, translated text.\n   - Keep non-speech text (e.g., `[Music]`) untranslated.\n   - Separate cues with a blank line.\n\n**Output:** Only the pure VTT content.\n\n**Example:**\n```vtt\nWEBVTT\n\n1000 --> 3500\nHello world!\n你好，世界！\n\n4000 --> 6000\nGood morning.\n早上好。\n```",
      "userPrompt": "",
      "tone": "formal",
      "placeholder": "{ }",
      "placetag": [
        "i"
      ],
      "customHeader": "",
      "customBody": "",
      "reqHook": "",
      "resHook": "",
      "fetchLimit": 10,
      "fetchInterval": 100,
      "httpTimeout": 300000,
      "batchInterval": 1000,
      "batchSize": 10,
      "batchLength": 10000,
      "useBatchFetch": false,
      "useContext": false,
      "contextSize": 3,
      "temperature": 0,
      "maxTokens": 20480,
      "think": false,
      "thinkIgnore": "qwen3,deepseek-r1",
      "isDisabled": false,
      "region": ""
    },
    {
      "apiSlug": "Google",
      "apiName": "Google",
      "apiType": "Google",
      "url": "https://translate.googleapis.com/translate_a/single",
      "key": "",
      "model": "",
      "systemPrompt": "Act as a translation API. Output a single raw JSON object only. No extra text or fences.\n\nInput:\n{\"targetLanguage\":\"<lang>\",\"title\":\"<context>\",\"description\":\"<context>\",\"segments\":[{\"id\":1,\"text\":\"...\"}],\"glossary\":{\"sourceTerm\":\"targetTerm\"},\"tone\":\"<formal|casual>\"}\n\nOutput:\n{\"translations\":[{\"id\":1,\"text\":\"...\",\"sourceLanguage\":\"<detected>\"}]}\n\nRules:\n1.  Use title/description for context only; do not output them.\n2.  Keep id, order, and count of segments.\n3.  Preserve whitespace, HTML entities, and all HTML-like tags (e.g., <i1>, <a1>). Translate inner text only.\n4.  Highest priority: Follow 'glossary'. Use value for translation; if value is \"\", keep the key.\n5.  Do not translate: content in <code>, <pre>, text enclosed in backticks, or placeholders like {1}, {{1}}, [1], [[1]].\n6.  Apply the specified tone to the translation.\n7.  Detect sourceLanguage for each segment.\n8.  Return empty or unchanged inputs as is.\n\nExample:\nInput: {\"targetLanguage\":\"zh-CN\",\"segments\":[{\"id\":1,\"text\":\"A <b>React</b> component.\"}],\"glossary\":{\"component\":\"组件\",\"React\":\"\"}}\nOutput: {\"translations\":[{\"id\":1,\"text\":\"一个<b>React</b>组件\",\"sourceLanguage\":\"en\"}]}\n\nFail-safe: On any error, return {\"translations\":[]}.",
      "subtitlePrompt": "You are an expert AI for subtitle generation. Convert a JSON array of word-level timestamps into a bilingual VTT file.\n\n**Workflow:**\n1. Merge `text` fields into complete sentences; ignore empty text.\n2. Split long sentences into smaller, manageable subtitle cues (one sentence per cue).\n3. Translate each cue into {{to}}.\n4. Format as VTT:\n   - Start with `WEBVTT`.\n   - Each cue: timestamps (`start --> end` in milliseconds), original text, translated text.\n   - Keep non-speech text (e.g., `[Music]`) untranslated.\n   - Separate cues with a blank line.\n\n**Output:** Only the pure VTT content.\n\n**Example:**\n```vtt\nWEBVTT\n\n1000 --> 3500\nHello world!\n你好，世界！\n\n4000 --> 6000\nGood morning.\n早上好。\n```",
      "userPrompt": "",
      "tone": "formal",
      "placeholder": "{ }",
      "placetag": [
        "i"
      ],
      "customHeader": "",
      "customBody": "",
      "reqHook": "",
      "resHook": "",
      "fetchLimit": 10,
      "fetchInterval": 100,
      "httpTimeout": 300000,
      "batchInterval": 1000,
      "batchSize": 10,
      "batchLength": 10000,
      "useBatchFetch": false,
      "useContext": false,
      "contextSize": 3,
      "temperature": 0,
      "maxTokens": 20480,
      "think": false,
      "thinkIgnore": "qwen3,deepseek-r1",
      "isDisabled": false,
      "region": ""
    },
    {
      "apiSlug": "Google2",
      "apiName": "Google2",
      "apiType": "Google2",
      "url": "https://translate-pa.googleapis.com/v1/translateHtml",
      "key": "AIzaSyATBXajvzQLTDHEQbcpq0Ihe0vWDHmO520",
      "model": "",
      "systemPrompt": "Act as a translation API. Output a single raw JSON object only. No extra text or fences.\n\nInput:\n{\"targetLanguage\":\"<lang>\",\"title\":\"<context>\",\"description\":\"<context>\",\"segments\":[{\"id\":1,\"text\":\"...\"}],\"glossary\":{\"sourceTerm\":\"targetTerm\"},\"tone\":\"<formal|casual>\"}\n\nOutput:\n{\"translations\":[{\"id\":1,\"text\":\"...\",\"sourceLanguage\":\"<detected>\"}]}\n\nRules:\n1.  Use title/description for context only; do not output them.\n2.  Keep id, order, and count of segments.\n3.  Preserve whitespace, HTML entities, and all HTML-like tags (e.g., <i1>, <a1>). Translate inner text only.\n4.  Highest priority: Follow 'glossary'. Use value for translation; if value is \"\", keep the key.\n5.  Do not translate: content in <code>, <pre>, text enclosed in backticks, or placeholders like {1}, {{1}}, [1], [[1]].\n6.  Apply the specified tone to the translation.\n7.  Detect sourceLanguage for each segment.\n8.  Return empty or unchanged inputs as is.\n\nExample:\nInput: {\"targetLanguage\":\"zh-CN\",\"segments\":[{\"id\":1,\"text\":\"A <b>React</b> component.\"}],\"glossary\":{\"component\":\"组件\",\"React\":\"\"}}\nOutput: {\"translations\":[{\"id\":1,\"text\":\"一个<b>React</b>组件\",\"sourceLanguage\":\"en\"}]}\n\nFail-safe: On any error, return {\"translations\":[]}.",
      "subtitlePrompt": "You are an expert AI for subtitle generation. Convert a JSON array of word-level timestamps into a bilingual VTT file.\n\n**Workflow:**\n1. Merge `text` fields into complete sentences; ignore empty text.\n2. Split long sentences into smaller, manageable subtitle cues (one sentence per cue).\n3. Translate each cue into {{to}}.\n4. Format as VTT:\n   - Start with `WEBVTT`.\n   - Each cue: timestamps (`start --> end` in milliseconds), original text, translated text.\n   - Keep non-speech text (e.g., `[Music]`) untranslated.\n   - Separate cues with a blank line.\n\n**Output:** Only the pure VTT content.\n\n**Example:**\n```vtt\nWEBVTT\n\n1000 --> 3500\nHello world!\n你好，世界！\n\n4000 --> 6000\nGood morning.\n早上好。\n```",
      "userPrompt": "",
      "tone": "formal",
      "placeholder": "{ }",
      "placetag": [
        "i"
      ],
      "customHeader": "",
      "customBody": "",
      "reqHook": "",
      "resHook": "",
      "fetchLimit": 10,
      "fetchInterval": 100,
      "httpTimeout": 300000,
      "batchInterval": 1000,
      "batchSize": 10,
      "batchLength": 10000,
      "useBatchFetch": true,
      "useContext": false,
      "contextSize": 3,
      "temperature": 0,
      "maxTokens": 20480,
      "think": false,
      "thinkIgnore": "qwen3,deepseek-r1",
      "isDisabled": false,
      "region": ""
    },
    {
      "apiSlug": "Microsoft",
      "apiName": "Microsoft",
      "apiType": "Microsoft",
      "url": "",
      "key": "",
      "model": "",
      "systemPrompt": "Act as a translation API. Output a single raw JSON object only. No extra text or fences.\n\nInput:\n{\"targetLanguage\":\"<lang>\",\"title\":\"<context>\",\"description\":\"<context>\",\"segments\":[{\"id\":1,\"text\":\"...\"}],\"glossary\":{\"sourceTerm\":\"targetTerm\"},\"tone\":\"<formal|casual>\"}\n\nOutput:\n{\"translations\":[{\"id\":1,\"text\":\"...\",\"sourceLanguage\":\"<detected>\"}]}\n\nRules:\n1.  Use title/description for context only; do not output them.\n2.  Keep id, order, and count of segments.\n3.  Preserve whitespace, HTML entities, and all HTML-like tags (e.g., <i1>, <a1>). Translate inner text only.\n4.  Highest priority: Follow 'glossary'. Use value for translation; if value is \"\", keep the key.\n5.  Do not translate: content in <code>, <pre>, text enclosed in backticks, or placeholders like {1}, {{1}}, [1], [[1]].\n6.  Apply the specified tone to the translation.\n7.  Detect sourceLanguage for each segment.\n8.  Return empty or unchanged inputs as is.\n\nExample:\nInput: {\"targetLanguage\":\"zh-CN\",\"segments\":[{\"id\":1,\"text\":\"A <b>React</b> component.\"}],\"glossary\":{\"component\":\"组件\",\"React\":\"\"}}\nOutput: {\"translations\":[{\"id\":1,\"text\":\"一个<b>React</b>组件\",\"sourceLanguage\":\"en\"}]}\n\nFail-safe: On any error, return {\"translations\":[]}.",
      "subtitlePrompt": "You are an expert AI for subtitle generation. Convert a JSON array of word-level timestamps into a bilingual VTT file.\n\n**Workflow:**\n1. Merge `text` fields into complete sentences; ignore empty text.\n2. Split long sentences into smaller, manageable subtitle cues (one sentence per cue).\n3. Translate each cue into {{to}}.\n4. Format as VTT:\n   - Start with `WEBVTT`.\n   - Each cue: timestamps (`start --> end` in milliseconds), original text, translated text.\n   - Keep non-speech text (e.g., `[Music]`) untranslated.\n   - Separate cues with a blank line.\n\n**Output:** Only the pure VTT content.\n\n**Example:**\n```vtt\nWEBVTT\n\n1000 --> 3500\nHello world!\n你好，世界！\n\n4000 --> 6000\nGood morning.\n早上好。\n```",
      "userPrompt": "",
      "tone": "formal",
      "placeholder": "{ }",
      "placetag": [
        "i"
      ],
      "customHeader": "",
      "customBody": "",
      "reqHook": "",
      "resHook": "",
      "fetchLimit": 10,
      "fetchInterval": 100,
      "httpTimeout": 300000,
      "batchInterval": 1000,
      "batchSize": 10,
      "batchLength": 10000,
      "useBatchFetch": true,
      "useContext": false,
      "contextSize": 3,
      "temperature": 0,
      "maxTokens": 20480,
      "think": false,
      "thinkIgnore": "qwen3,deepseek-r1",
      "isDisabled": false,
      "region": ""
    },
    {
      "apiSlug": "AzureAI",
      "apiName": "AzureAI",
      "apiType": "AzureAI",
      "url": "https://api.cognitive.microsofttranslator.com/translate?api-version=3.0",
      "key": "",
      "model": "",
      "systemPrompt": "Act as a translation API. Output a single raw JSON object only. No extra text or fences.\n\nInput:\n{\"targetLanguage\":\"<lang>\",\"title\":\"<context>\",\"description\":\"<context>\",\"segments\":[{\"id\":1,\"text\":\"...\"}],\"glossary\":{\"sourceTerm\":\"targetTerm\"},\"tone\":\"<formal|casual>\"}\n\nOutput:\n{\"translations\":[{\"id\":1,\"text\":\"...\",\"sourceLanguage\":\"<detected>\"}]}\n\nRules:\n1.  Use title/description for context only; do not output them.\n2.  Keep id, order, and count of segments.\n3.  Preserve whitespace, HTML entities, and all HTML-like tags (e.g., <i1>, <a1>). Translate inner text only.\n4.  Highest priority: Follow 'glossary'. Use value for translation; if value is \"\", keep the key.\n5.  Do not translate: content in <code>, <pre>, text enclosed in backticks, or placeholders like {1}, {{1}}, [1], [[1]].\n6.  Apply the specified tone to the translation.\n7.  Detect sourceLanguage for each segment.\n8.  Return empty or unchanged inputs as is.\n\nExample:\nInput: {\"targetLanguage\":\"zh-CN\",\"segments\":[{\"id\":1,\"text\":\"A <b>React</b> component.\"}],\"glossary\":{\"component\":\"组件\",\"React\":\"\"}}\nOutput: {\"translations\":[{\"id\":1,\"text\":\"一个<b>React</b>组件\",\"sourceLanguage\":\"en\"}]}\n\nFail-safe: On any error, return {\"translations\":[]}.",
      "subtitlePrompt": "You are an expert AI for subtitle generation. Convert a JSON array of word-level timestamps into a bilingual VTT file.\n\n**Workflow:**\n1. Merge `text` fields into complete sentences; ignore empty text.\n2. Split long sentences into smaller, manageable subtitle cues (one sentence per cue).\n3. Translate each cue into {{to}}.\n4. Format as VTT:\n   - Start with `WEBVTT`.\n   - Each cue: timestamps (`start --> end` in milliseconds), original text, translated text.\n   - Keep non-speech text (e.g., `[Music]`) untranslated.\n   - Separate cues with a blank line.\n\n**Output:** Only the pure VTT content.\n\n**Example:**\n```vtt\nWEBVTT\n\n1000 --> 3500\nHello world!\n你好，世界！\n\n4000 --> 6000\nGood morning.\n早上好。\n```",
      "userPrompt": "",
      "tone": "formal",
      "placeholder": "{ }",
      "placetag": [
        "i"
      ],
      "customHeader": "",
      "customBody": "",
      "reqHook": "",
      "resHook": "",
      "fetchLimit": 10,
      "fetchInterval": 100,
      "httpTimeout": 300000,
      "batchInterval": 1000,
      "batchSize": 10,
      "batchLength": 10000,
      "useBatchFetch": true,
      "useContext": false,
      "contextSize": 3,
      "temperature": 0,
      "maxTokens": 20480,
      "think": false,
      "thinkIgnore": "qwen3,deepseek-r1",
      "isDisabled": false,
      "region": ""
    },
    {
      "apiSlug": "Tencent",
      "apiName": "Tencent",
      "apiType": "Tencent",
      "url": "",
      "key": "",
      "model": "",
      "systemPrompt": "Act as a translation API. Output a single raw JSON object only. No extra text or fences.\n\nInput:\n{\"targetLanguage\":\"<lang>\",\"title\":\"<context>\",\"description\":\"<context>\",\"segments\":[{\"id\":1,\"text\":\"...\"}],\"glossary\":{\"sourceTerm\":\"targetTerm\"},\"tone\":\"<formal|casual>\"}\n\nOutput:\n{\"translations\":[{\"id\":1,\"text\":\"...\",\"sourceLanguage\":\"<detected>\"}]}\n\nRules:\n1.  Use title/description for context only; do not output them.\n2.  Keep id, order, and count of segments.\n3.  Preserve whitespace, HTML entities, and all HTML-like tags (e.g., <i1>, <a1>). Translate inner text only.\n4.  Highest priority: Follow 'glossary'. Use value for translation; if value is \"\", keep the key.\n5.  Do not translate: content in <code>, <pre>, text enclosed in backticks, or placeholders like {1}, {{1}}, [1], [[1]].\n6.  Apply the specified tone to the translation.\n7.  Detect sourceLanguage for each segment.\n8.  Return empty or unchanged inputs as is.\n\nExample:\nInput: {\"targetLanguage\":\"zh-CN\",\"segments\":[{\"id\":1,\"text\":\"A <b>React</b> component.\"}],\"glossary\":{\"component\":\"组件\",\"React\":\"\"}}\nOutput: {\"translations\":[{\"id\":1,\"text\":\"一个<b>React</b>组件\",\"sourceLanguage\":\"en\"}]}\n\nFail-safe: On any error, return {\"translations\":[]}.",
      "subtitlePrompt": "You are an expert AI for subtitle generation. Convert a JSON array of word-level timestamps into a bilingual VTT file.\n\n**Workflow:**\n1. Merge `text` fields into complete sentences; ignore empty text.\n2. Split long sentences into smaller, manageable subtitle cues (one sentence per cue).\n3. Translate each cue into {{to}}.\n4. Format as VTT:\n   - Start with `WEBVTT`.\n   - Each cue: timestamps (`start --> end` in milliseconds), original text, translated text.\n   - Keep non-speech text (e.g., `[Music]`) untranslated.\n   - Separate cues with a blank line.\n\n**Output:** Only the pure VTT content.\n\n**Example:**\n```vtt\nWEBVTT\n\n1000 --> 3500\nHello world!\n你好，世界！\n\n4000 --> 6000\nGood morning.\n早上好。\n```",
      "userPrompt": "",
      "tone": "formal",
      "placeholder": "{ }",
      "placetag": [
        "i"
      ],
      "customHeader": "",
      "customBody": "",
      "reqHook": "",
      "resHook": "",
      "fetchLimit": 10,
      "fetchInterval": 100,
      "httpTimeout": 300000,
      "batchInterval": 1000,
      "batchSize": 10,
      "batchLength": 10000,
      "useBatchFetch": true,
      "useContext": false,
      "contextSize": 3,
      "temperature": 0,
      "maxTokens": 20480,
      "think": false,
      "thinkIgnore": "qwen3,deepseek-r1",
      "isDisabled": false,
      "region": ""
    },
    {
      "apiSlug": "Volcengine",
      "apiName": "Volcengine",
      "apiType": "Volcengine",
      "url": "",
      "key": "",
      "model": "",
      "systemPrompt": "Act as a translation API. Output a single raw JSON object only. No extra text or fences.\n\nInput:\n{\"targetLanguage\":\"<lang>\",\"title\":\"<context>\",\"description\":\"<context>\",\"segments\":[{\"id\":1,\"text\":\"...\"}],\"glossary\":{\"sourceTerm\":\"targetTerm\"},\"tone\":\"<formal|casual>\"}\n\nOutput:\n{\"translations\":[{\"id\":1,\"text\":\"...\",\"sourceLanguage\":\"<detected>\"}]}\n\nRules:\n1.  Use title/description for context only; do not output them.\n2.  Keep id, order, and count of segments.\n3.  Preserve whitespace, HTML entities, and all HTML-like tags (e.g., <i1>, <a1>). Translate inner text only.\n4.  Highest priority: Follow 'glossary'. Use value for translation; if value is \"\", keep the key.\n5.  Do not translate: content in <code>, <pre>, text enclosed in backticks, or placeholders like {1}, {{1}}, [1], [[1]].\n6.  Apply the specified tone to the translation.\n7.  Detect sourceLanguage for each segment.\n8.  Return empty or unchanged inputs as is.\n\nExample:\nInput: {\"targetLanguage\":\"zh-CN\",\"segments\":[{\"id\":1,\"text\":\"A <b>React</b> component.\"}],\"glossary\":{\"component\":\"组件\",\"React\":\"\"}}\nOutput: {\"translations\":[{\"id\":1,\"text\":\"一个<b>React</b>组件\",\"sourceLanguage\":\"en\"}]}\n\nFail-safe: On any error, return {\"translations\":[]}.",
      "subtitlePrompt": "You are an expert AI for subtitle generation. Convert a JSON array of word-level timestamps into a bilingual VTT file.\n\n**Workflow:**\n1. Merge `text` fields into complete sentences; ignore empty text.\n2. Split long sentences into smaller, manageable subtitle cues (one sentence per cue).\n3. Translate each cue into {{to}}.\n4. Format as VTT:\n   - Start with `WEBVTT`.\n   - Each cue: timestamps (`start --> end` in milliseconds), original text, translated text.\n   - Keep non-speech text (e.g., `[Music]`) untranslated.\n   - Separate cues with a blank line.\n\n**Output:** Only the pure VTT content.\n\n**Example:**\n```vtt\nWEBVTT\n\n1000 --> 3500\nHello world!\n你好，世界！\n\n4000 --> 6000\nGood morning.\n早上好。\n```",
      "userPrompt": "",
      "tone": "formal",
      "placeholder": "{ }",
      "placetag": [
        "i"
      ],
      "customHeader": "",
      "customBody": "",
      "reqHook": "",
      "resHook": "",
      "fetchLimit": 10,
      "fetchInterval": 100,
      "httpTimeout": 300000,
      "batchInterval": 1000,
      "batchSize": 10,
      "batchLength": 10000,
      "useBatchFetch": false,
      "useContext": false,
      "contextSize": 3,
      "temperature": 0,
      "maxTokens": 20480,
      "think": false,
      "thinkIgnore": "qwen3,deepseek-r1",
      "isDisabled": false,
      "region": ""
    },
    {
      "apiSlug": "DeepL",
      "apiName": "DeepL",
      "apiType": "DeepL",
      "url": "https://api-free.deepl.com/v2/translate",
      "key": "",
      "model": "",
      "systemPrompt": "Act as a translation API. Output a single raw JSON object only. No extra text or fences.\n\nInput:\n{\"targetLanguage\":\"<lang>\",\"title\":\"<context>\",\"description\":\"<context>\",\"segments\":[{\"id\":1,\"text\":\"...\"}],\"glossary\":{\"sourceTerm\":\"targetTerm\"},\"tone\":\"<formal|casual>\"}\n\nOutput:\n{\"translations\":[{\"id\":1,\"text\":\"...\",\"sourceLanguage\":\"<detected>\"}]}\n\nRules:\n1.  Use title/description for context only; do not output them.\n2.  Keep id, order, and count of segments.\n3.  Preserve whitespace, HTML entities, and all HTML-like tags (e.g., <i1>, <a1>). Translate inner text only.\n4.  Highest priority: Follow 'glossary'. Use value for translation; if value is \"\", keep the key.\n5.  Do not translate: content in <code>, <pre>, text enclosed in backticks, or placeholders like {1}, {{1}}, [1], [[1]].\n6.  Apply the specified tone to the translation.\n7.  Detect sourceLanguage for each segment.\n8.  Return empty or unchanged inputs as is.\n\nExample:\nInput: {\"targetLanguage\":\"zh-CN\",\"segments\":[{\"id\":1,\"text\":\"A <b>React</b> component.\"}],\"glossary\":{\"component\":\"组件\",\"React\":\"\"}}\nOutput: {\"translations\":[{\"id\":1,\"text\":\"一个<b>React</b>组件\",\"sourceLanguage\":\"en\"}]}\n\nFail-safe: On any error, return {\"translations\":[]}.",
      "subtitlePrompt": "You are an expert AI for subtitle generation. Convert a JSON array of word-level timestamps into a bilingual VTT file.\n\n**Workflow:**\n1. Merge `text` fields into complete sentences; ignore empty text.\n2. Split long sentences into smaller, manageable subtitle cues (one sentence per cue).\n3. Translate each cue into {{to}}.\n4. Format as VTT:\n   - Start with `WEBVTT`.\n   - Each cue: timestamps (`start --> end` in milliseconds), original text, translated text.\n   - Keep non-speech text (e.g., `[Music]`) untranslated.\n   - Separate cues with a blank line.\n\n**Output:** Only the pure VTT content.\n\n**Example:**\n```vtt\nWEBVTT\n\n1000 --> 3500\nHello world!\n你好，世界！\n\n4000 --> 6000\nGood morning.\n早上好。\n```",
      "userPrompt": "",
      "tone": "formal",
      "placeholder": "{ }",
      "placetag": [
        "i"
      ],
      "customHeader": "",
      "customBody": "",
      "reqHook": "",
      "resHook": "",
      "fetchLimit": 10,
      "fetchInterval": 100,
      "httpTimeout": 300000,
      "batchInterval": 1000,
      "batchSize": 10,
      "batchLength": 10000,
      "useBatchFetch": true,
      "useContext": false,
      "contextSize": 3,
      "temperature": 0,
      "maxTokens": 20480,
      "think": false,
      "thinkIgnore": "qwen3,deepseek-r1",
      "isDisabled": false,
      "region": ""
    },
    {
      "apiSlug": "DeepLFree",
      "apiName": "DeepLFree",
      "apiType": "DeepLFree",
      "url": "",
      "key": "",
      "model": "",
      "systemPrompt": "Act as a translation API. Output a single raw JSON object only. No extra text or fences.\n\nInput:\n{\"targetLanguage\":\"<lang>\",\"title\":\"<context>\",\"description\":\"<context>\",\"segments\":[{\"id\":1,\"text\":\"...\"}],\"glossary\":{\"sourceTerm\":\"targetTerm\"},\"tone\":\"<formal|casual>\"}\n\nOutput:\n{\"translations\":[{\"id\":1,\"text\":\"...\",\"sourceLanguage\":\"<detected>\"}]}\n\nRules:\n1.  Use title/description for context only; do not output them.\n2.  Keep id, order, and count of segments.\n3.  Preserve whitespace, HTML entities, and all HTML-like tags (e.g., <i1>, <a1>). Translate inner text only.\n4.  Highest priority: Follow 'glossary'. Use value for translation; if value is \"\", keep the key.\n5.  Do not translate: content in <code>, <pre>, text enclosed in backticks, or placeholders like {1}, {{1}}, [1], [[1]].\n6.  Apply the specified tone to the translation.\n7.  Detect sourceLanguage for each segment.\n8.  Return empty or unchanged inputs as is.\n\nExample:\nInput: {\"targetLanguage\":\"zh-CN\",\"segments\":[{\"id\":1,\"text\":\"A <b>React</b> component.\"}],\"glossary\":{\"component\":\"组件\",\"React\":\"\"}}\nOutput: {\"translations\":[{\"id\":1,\"text\":\"一个<b>React</b>组件\",\"sourceLanguage\":\"en\"}]}\n\nFail-safe: On any error, return {\"translations\":[]}.",
      "subtitlePrompt": "You are an expert AI for subtitle generation. Convert a JSON array of word-level timestamps into a bilingual VTT file.\n\n**Workflow:**\n1. Merge `text` fields into complete sentences; ignore empty text.\n2. Split long sentences into smaller, manageable subtitle cues (one sentence per cue).\n3. Translate each cue into {{to}}.\n4. Format as VTT:\n   - Start with `WEBVTT`.\n   - Each cue: timestamps (`start --> end` in milliseconds), original text, translated text.\n   - Keep non-speech text (e.g., `[Music]`) untranslated.\n   - Separate cues with a blank line.\n\n**Output:** Only the pure VTT content.\n\n**Example:**\n```vtt\nWEBVTT\n\n1000 --> 3500\nHello world!\n你好，世界！\n\n4000 --> 6000\nGood morning.\n早上好。\n```",
      "userPrompt": "",
      "tone": "formal",
      "placeholder": "{ }",
      "placetag": [
        "i"
      ],
      "customHeader": "",
      "customBody": "",
      "reqHook": "",
      "resHook": "",
      "fetchLimit": 1,
      "fetchInterval": 100,
      "httpTimeout": 300000,
      "batchInterval": 1000,
      "batchSize": 10,
      "batchLength": 10000,
      "useBatchFetch": false,
      "useContext": false,
      "contextSize": 3,
      "temperature": 0,
      "maxTokens": 20480,
      "think": false,
      "thinkIgnore": "qwen3,deepseek-r1",
      "isDisabled": false,
      "region": ""
    },
    {
      "apiSlug": "DeepLX",
      "apiName": "DeepLX",
      "apiType": "DeepLX",
      "url": "http://localhost:1188/translate",
      "key": "",
      "model": "",
      "systemPrompt": "Act as a translation API. Output a single raw JSON object only. No extra text or fences.\n\nInput:\n{\"targetLanguage\":\"<lang>\",\"title\":\"<context>\",\"description\":\"<context>\",\"segments\":[{\"id\":1,\"text\":\"...\"}],\"glossary\":{\"sourceTerm\":\"targetTerm\"},\"tone\":\"<formal|casual>\"}\n\nOutput:\n{\"translations\":[{\"id\":1,\"text\":\"...\",\"sourceLanguage\":\"<detected>\"}]}\n\nRules:\n1.  Use title/description for context only; do not output them.\n2.  Keep id, order, and count of segments.\n3.  Preserve whitespace, HTML entities, and all HTML-like tags (e.g., <i1>, <a1>). Translate inner text only.\n4.  Highest priority: Follow 'glossary'. Use value for translation; if value is \"\", keep the key.\n5.  Do not translate: content in <code>, <pre>, text enclosed in backticks, or placeholders like {1}, {{1}}, [1], [[1]].\n6.  Apply the specified tone to the translation.\n7.  Detect sourceLanguage for each segment.\n8.  Return empty or unchanged inputs as is.\n\nExample:\nInput: {\"targetLanguage\":\"zh-CN\",\"segments\":[{\"id\":1,\"text\":\"A <b>React</b> component.\"}],\"glossary\":{\"component\":\"组件\",\"React\":\"\"}}\nOutput: {\"translations\":[{\"id\":1,\"text\":\"一个<b>React</b>组件\",\"sourceLanguage\":\"en\"}]}\n\nFail-safe: On any error, return {\"translations\":[]}.",
      "subtitlePrompt": "You are an expert AI for subtitle generation. Convert a JSON array of word-level timestamps into a bilingual VTT file.\n\n**Workflow:**\n1. Merge `text` fields into complete sentences; ignore empty text.\n2. Split long sentences into smaller, manageable subtitle cues (one sentence per cue).\n3. Translate each cue into {{to}}.\n4. Format as VTT:\n   - Start with `WEBVTT`.\n   - Each cue: timestamps (`start --> end` in milliseconds), original text, translated text.\n   - Keep non-speech text (e.g., `[Music]`) untranslated.\n   - Separate cues with a blank line.\n\n**Output:** Only the pure VTT content.\n\n**Example:**\n```vtt\nWEBVTT\n\n1000 --> 3500\nHello world!\n你好，世界！\n\n4000 --> 6000\nGood morning.\n早上好。\n```",
      "userPrompt": "",
      "tone": "formal",
      "placeholder": "{ }",
      "placetag": [
        "i"
      ],
      "customHeader": "",
      "customBody": "",
      "reqHook": "",
      "resHook": "",
      "fetchLimit": 1,
      "fetchInterval": 100,
      "httpTimeout": 300000,
      "batchInterval": 1000,
      "batchSize": 10,
      "batchLength": 10000,
      "useBatchFetch": false,
      "useContext": false,
      "contextSize": 3,
      "temperature": 0,
      "maxTokens": 20480,
      "think": false,
      "thinkIgnore": "qwen3,deepseek-r1",
      "isDisabled": false,
      "region": ""
    },
    {
      "apiSlug": "NiuTrans",
      "apiName": "NiuTrans",
      "apiType": "NiuTrans",
      "url": "https://api.niutrans.com/NiuTransServer/translation",
      "key": "",
      "model": "",
      "systemPrompt": "Act as a translation API. Output a single raw JSON object only. No extra text or fences.\n\nInput:\n{\"targetLanguage\":\"<lang>\",\"title\":\"<context>\",\"description\":\"<context>\",\"segments\":[{\"id\":1,\"text\":\"...\"}],\"glossary\":{\"sourceTerm\":\"targetTerm\"},\"tone\":\"<formal|casual>\"}\n\nOutput:\n{\"translations\":[{\"id\":1,\"text\":\"...\",\"sourceLanguage\":\"<detected>\"}]}\n\nRules:\n1.  Use title/description for context only; do not output them.\n2.  Keep id, order, and count of segments.\n3.  Preserve whitespace, HTML entities, and all HTML-like tags (e.g., <i1>, <a1>). Translate inner text only.\n4.  Highest priority: Follow 'glossary'. Use value for translation; if value is \"\", keep the key.\n5.  Do not translate: content in <code>, <pre>, text enclosed in backticks, or placeholders like {1}, {{1}}, [1], [[1]].\n6.  Apply the specified tone to the translation.\n7.  Detect sourceLanguage for each segment.\n8.  Return empty or unchanged inputs as is.\n\nExample:\nInput: {\"targetLanguage\":\"zh-CN\",\"segments\":[{\"id\":1,\"text\":\"A <b>React</b> component.\"}],\"glossary\":{\"component\":\"组件\",\"React\":\"\"}}\nOutput: {\"translations\":[{\"id\":1,\"text\":\"一个<b>React</b>组件\",\"sourceLanguage\":\"en\"}]}\n\nFail-safe: On any error, return {\"translations\":[]}.",
      "subtitlePrompt": "You are an expert AI for subtitle generation. Convert a JSON array of word-level timestamps into a bilingual VTT file.\n\n**Workflow:**\n1. Merge `text` fields into complete sentences; ignore empty text.\n2. Split long sentences into smaller, manageable subtitle cues (one sentence per cue).\n3. Translate each cue into {{to}}.\n4. Format as VTT:\n   - Start with `WEBVTT`.\n   - Each cue: timestamps (`start --> end` in milliseconds), original text, translated text.\n   - Keep non-speech text (e.g., `[Music]`) untranslated.\n   - Separate cues with a blank line.\n\n**Output:** Only the pure VTT content.\n\n**Example:**\n```vtt\nWEBVTT\n\n1000 --> 3500\nHello world!\n你好，世界！\n\n4000 --> 6000\nGood morning.\n早上好。\n```",
      "userPrompt": "",
      "tone": "formal",
      "placeholder": "{ }",
      "placetag": [
        "i"
      ],
      "customHeader": "",
      "customBody": "",
      "reqHook": "",
      "resHook": "",
      "fetchLimit": 10,
      "fetchInterval": 100,
      "httpTimeout": 300000,
      "batchInterval": 1000,
      "batchSize": 10,
      "batchLength": 10000,
      "useBatchFetch": false,
      "useContext": false,
      "contextSize": 3,
      "temperature": 0,
      "maxTokens": 20480,
      "think": false,
      "thinkIgnore": "qwen3,deepseek-r1",
      "isDisabled": false,
      "region": "",
      "dictNo": "",
      "memoryNo": ""
    },
    {
      "apiSlug": "OpenAI",
      "apiName": "OpenAI",
      "apiType": "OpenAI",
      "url": "https://api.openai.com/v1/chat/completions",
      "key": "",
      "model": "gpt-4",
      "systemPrompt": "Act as a translation API. Output a single raw JSON object only. No extra text or fences.\n\nInput:\n{\"targetLanguage\":\"<lang>\",\"title\":\"<context>\",\"description\":\"<context>\",\"segments\":[{\"id\":1,\"text\":\"...\"}],\"glossary\":{\"sourceTerm\":\"targetTerm\"},\"tone\":\"<formal|casual>\"}\n\nOutput:\n{\"translations\":[{\"id\":1,\"text\":\"...\",\"sourceLanguage\":\"<detected>\"}]}\n\nRules:\n1.  Use title/description for context only; do not output them.\n2.  Keep id, order, and count of segments.\n3.  Preserve whitespace, HTML entities, and all HTML-like tags (e.g., <i1>, <a1>). Translate inner text only.\n4.  Highest priority: Follow 'glossary'. Use value for translation; if value is \"\", keep the key.\n5.  Do not translate: content in <code>, <pre>, text enclosed in backticks, or placeholders like {1}, {{1}}, [1], [[1]].\n6.  Apply the specified tone to the translation.\n7.  Detect sourceLanguage for each segment.\n8.  Return empty or unchanged inputs as is.\n\nExample:\nInput: {\"targetLanguage\":\"zh-CN\",\"segments\":[{\"id\":1,\"text\":\"A <b>React</b> component.\"}],\"glossary\":{\"component\":\"组件\",\"React\":\"\"}}\nOutput: {\"translations\":[{\"id\":1,\"text\":\"一个<b>React</b>组件\",\"sourceLanguage\":\"en\"}]}\n\nFail-safe: On any error, return {\"translations\":[]}.",
      "subtitlePrompt": "You are an expert AI for subtitle generation. Convert a JSON array of word-level timestamps into a bilingual VTT file.\n\n**Workflow:**\n1. Merge `text` fields into complete sentences; ignore empty text.\n2. Split long sentences into smaller, manageable subtitle cues (one sentence per cue).\n3. Translate each cue into {{to}}.\n4. Format as VTT:\n   - Start with `WEBVTT`.\n   - Each cue: timestamps (`start --> end` in milliseconds), original text, translated text.\n   - Keep non-speech text (e.g., `[Music]`) untranslated.\n   - Separate cues with a blank line.\n\n**Output:** Only the pure VTT content.\n\n**Example:**\n```vtt\nWEBVTT\n\n1000 --> 3500\nHello world!\n你好，世界！\n\n4000 --> 6000\nGood morning.\n早上好。\n```",
      "userPrompt": "",
      "tone": "formal",
      "placeholder": "{ }",
      "placetag": [
        "i"
      ],
      "customHeader": "",
      "customBody": "",
      "reqHook": "",
      "resHook": "",
      "fetchLimit": 1,
      "fetchInterval": 100,
      "httpTimeout": 300000,
      "batchInterval": 1000,
      "batchSize": 10,
      "batchLength": 10000,
      "useBatchFetch": true,
      "useContext": false,
      "contextSize": 3,
      "temperature": 0,
      "maxTokens": 20480,
      "think": false,
      "thinkIgnore": "qwen3,deepseek-r1",
      "isDisabled": false,
      "region": ""
    },
    {
      "apiSlug": "Gemini",
      "apiName": "Gemini",
      "apiType": "Gemini",
      "url": "https://generativelanguage.googleapis.com/v1/models/{{model}}:generateContent?key={{key}}",
      "key": "",
      "model": "gemini-2.5-flash",
      "systemPrompt": "Act as a translation API. Output a single raw JSON object only. No extra text or fences.\n\nInput:\n{\"targetLanguage\":\"<lang>\",\"title\":\"<context>\",\"description\":\"<context>\",\"segments\":[{\"id\":1,\"text\":\"...\"}],\"glossary\":{\"sourceTerm\":\"targetTerm\"},\"tone\":\"<formal|casual>\"}\n\nOutput:\n{\"translations\":[{\"id\":1,\"text\":\"...\",\"sourceLanguage\":\"<detected>\"}]}\n\nRules:\n1.  Use title/description for context only; do not output them.\n2.  Keep id, order, and count of segments.\n3.  Preserve whitespace, HTML entities, and all HTML-like tags (e.g., <i1>, <a1>). Translate inner text only.\n4.  Highest priority: Follow 'glossary'. Use value for translation; if value is \"\", keep the key.\n5.  Do not translate: content in <code>, <pre>, text enclosed in backticks, or placeholders like {1}, {{1}}, [1], [[1]].\n6.  Apply the specified tone to the translation.\n7.  Detect sourceLanguage for each segment.\n8.  Return empty or unchanged inputs as is.\n\nExample:\nInput: {\"targetLanguage\":\"zh-CN\",\"segments\":[{\"id\":1,\"text\":\"A <b>React</b> component.\"}],\"glossary\":{\"component\":\"组件\",\"React\":\"\"}}\nOutput: {\"translations\":[{\"id\":1,\"text\":\"一个<b>React</b>组件\",\"sourceLanguage\":\"en\"}]}\n\nFail-safe: On any error, return {\"translations\":[]}.",
      "subtitlePrompt": "You are an expert AI for subtitle generation. Convert a JSON array of word-level timestamps into a bilingual VTT file.\n\n**Workflow:**\n1. Merge `text` fields into complete sentences; ignore empty text.\n2. Split long sentences into smaller, manageable subtitle cues (one sentence per cue).\n3. Translate each cue into {{to}}.\n4. Format as VTT:\n   - Start with `WEBVTT`.\n   - Each cue: timestamps (`start --> end` in milliseconds), original text, translated text.\n   - Keep non-speech text (e.g., `[Music]`) untranslated.\n   - Separate cues with a blank line.\n\n**Output:** Only the pure VTT content.\n\n**Example:**\n```vtt\nWEBVTT\n\n1000 --> 3500\nHello world!\n你好，世界！\n\n4000 --> 6000\nGood morning.\n早上好。\n```",
      "userPrompt": "",
      "tone": "formal",
      "placeholder": "{ }",
      "placetag": [
        "i"
      ],
      "customHeader": "",
      "customBody": "",
      "reqHook": "",
      "resHook": "",
      "fetchLimit": 10,
      "fetchInterval": 100,
      "httpTimeout": 300000,
      "batchInterval": 1000,
      "batchSize": 10,
      "batchLength": 10000,
      "useBatchFetch": true,
      "useContext": false,
      "contextSize": 3,
      "temperature": 0,
      "maxTokens": 20480,
      "think": false,
      "thinkIgnore": "qwen3,deepseek-r1",
      "isDisabled": false,
      "region": ""
    },
    {
      "apiSlug": "Gemini2",
      "apiName": "Gemini2",
      "apiType": "Gemini2",
      "url": "https://generativelanguage.googleapis.com/v1beta/openai/chat/completions",
      "key": "",
      "model": "gemini-2.0-flash",
      "systemPrompt": "Act as a translation API. Output a single raw JSON object only. No extra text or fences.\n\nInput:\n{\"targetLanguage\":\"<lang>\",\"title\":\"<context>\",\"description\":\"<context>\",\"segments\":[{\"id\":1,\"text\":\"...\"}],\"glossary\":{\"sourceTerm\":\"targetTerm\"},\"tone\":\"<formal|casual>\"}\n\nOutput:\n{\"translations\":[{\"id\":1,\"text\":\"...\",\"sourceLanguage\":\"<detected>\"}]}\n\nRules:\n1.  Use title/description for context only; do not output them.\n2.  Keep id, order, and count of segments.\n3.  Preserve whitespace, HTML entities, and all HTML-like tags (e.g., <i1>, <a1>). Translate inner text only.\n4.  Highest priority: Follow 'glossary'. Use value for translation; if value is \"\", keep the key.\n5.  Do not translate: content in <code>, <pre>, text enclosed in backticks, or placeholders like {1}, {{1}}, [1], [[1]].\n6.  Apply the specified tone to the translation.\n7.  Detect sourceLanguage for each segment.\n8.  Return empty or unchanged inputs as is.\n\nExample:\nInput: {\"targetLanguage\":\"zh-CN\",\"segments\":[{\"id\":1,\"text\":\"A <b>React</b> component.\"}],\"glossary\":{\"component\":\"组件\",\"React\":\"\"}}\nOutput: {\"translations\":[{\"id\":1,\"text\":\"一个<b>React</b>组件\",\"sourceLanguage\":\"en\"}]}\n\nFail-safe: On any error, return {\"translations\":[]}.",
      "subtitlePrompt": "You are an expert AI for subtitle generation. Convert a JSON array of word-level timestamps into a bilingual VTT file.\n\n**Workflow:**\n1. Merge `text` fields into complete sentences; ignore empty text.\n2. Split long sentences into smaller, manageable subtitle cues (one sentence per cue).\n3. Translate each cue into {{to}}.\n4. Format as VTT:\n   - Start with `WEBVTT`.\n   - Each cue: timestamps (`start --> end` in milliseconds), original text, translated text.\n   - Keep non-speech text (e.g., `[Music]`) untranslated.\n   - Separate cues with a blank line.\n\n**Output:** Only the pure VTT content.\n\n**Example:**\n```vtt\nWEBVTT\n\n1000 --> 3500\nHello world!\n你好，世界！\n\n4000 --> 6000\nGood morning.\n早上好。\n```",
      "userPrompt": "",
      "tone": "formal",
      "placeholder": "{ }",
      "placetag": [
        "i"
      ],
      "customHeader": "",
      "customBody": "",
      "reqHook": "",
      "resHook": "",
      "fetchLimit": 10,
      "fetchInterval": 100,
      "httpTimeout": 300000,
      "batchInterval": 1000,
      "batchSize": 10,
      "batchLength": 10000,
      "useBatchFetch": true,
      "useContext": false,
      "contextSize": 3,
      "temperature": 0,
      "maxTokens": 20480,
      "think": false,
      "thinkIgnore": "qwen3,deepseek-r1",
      "isDisabled": false,
      "region": ""
    },
    {
      "apiSlug": "Claude",
      "apiName": "Claude",
      "apiType": "Claude",
      "url": "https://api.anthropic.com/v1/messages",
      "key": "",
      "model": "claude-3-haiku-20240307",
      "systemPrompt": "Act as a translation API. Output a single raw JSON object only. No extra text or fences.\n\nInput:\n{\"targetLanguage\":\"<lang>\",\"title\":\"<context>\",\"description\":\"<context>\",\"segments\":[{\"id\":1,\"text\":\"...\"}],\"glossary\":{\"sourceTerm\":\"targetTerm\"},\"tone\":\"<formal|casual>\"}\n\nOutput:\n{\"translations\":[{\"id\":1,\"text\":\"...\",\"sourceLanguage\":\"<detected>\"}]}\n\nRules:\n1.  Use title/description for context only; do not output them.\n2.  Keep id, order, and count of segments.\n3.  Preserve whitespace, HTML entities, and all HTML-like tags (e.g., <i1>, <a1>). Translate inner text only.\n4.  Highest priority: Follow 'glossary'. Use value for translation; if value is \"\", keep the key.\n5.  Do not translate: content in <code>, <pre>, text enclosed in backticks, or placeholders like {1}, {{1}}, [1], [[1]].\n6.  Apply the specified tone to the translation.\n7.  Detect sourceLanguage for each segment.\n8.  Return empty or unchanged inputs as is.\n\nExample:\nInput: {\"targetLanguage\":\"zh-CN\",\"segments\":[{\"id\":1,\"text\":\"A <b>React</b> component.\"}],\"glossary\":{\"component\":\"组件\",\"React\":\"\"}}\nOutput: {\"translations\":[{\"id\":1,\"text\":\"一个<b>React</b>组件\",\"sourceLanguage\":\"en\"}]}\n\nFail-safe: On any error, return {\"translations\":[]}.",
      "subtitlePrompt": "You are an expert AI for subtitle generation. Convert a JSON array of word-level timestamps into a bilingual VTT file.\n\n**Workflow:**\n1. Merge `text` fields into complete sentences; ignore empty text.\n2. Split long sentences into smaller, manageable subtitle cues (one sentence per cue).\n3. Translate each cue into {{to}}.\n4. Format as VTT:\n   - Start with `WEBVTT`.\n   - Each cue: timestamps (`start --> end` in milliseconds), original text, translated text.\n   - Keep non-speech text (e.g., `[Music]`) untranslated.\n   - Separate cues with a blank line.\n\n**Output:** Only the pure VTT content.\n\n**Example:**\n```vtt\nWEBVTT\n\n1000 --> 3500\nHello world!\n你好，世界！\n\n4000 --> 6000\nGood morning.\n早上好。\n```",
      "userPrompt": "",
      "tone": "formal",
      "placeholder": "{ }",
      "placetag": [
        "i"
      ],
      "customHeader": "",
      "customBody": "",
      "reqHook": "",
      "resHook": "",
      "fetchLimit": 10,
      "fetchInterval": 100,
      "httpTimeout": 300000,
      "batchInterval": 1000,
      "batchSize": 10,
      "batchLength": 10000,
      "useBatchFetch": true,
      "useContext": false,
      "contextSize": 3,
      "temperature": 0,
      "maxTokens": 20480,
      "think": false,
      "thinkIgnore": "qwen3,deepseek-r1",
      "isDisabled": false,
      "region": ""
    },
    {
      "apiSlug": "CloudflareAI",
      "apiName": "CloudflareAI",
      "apiType": "CloudflareAI",
      "url": "https://api.cloudflare.com/client/v4/accounts/{{ACCOUNT_ID}}/ai/run/@cf/meta/m2m100-1.2b",
      "key": "",
      "model": "",
      "systemPrompt": "Act as a translation API. Output a single raw JSON object only. No extra text or fences.\n\nInput:\n{\"targetLanguage\":\"<lang>\",\"title\":\"<context>\",\"description\":\"<context>\",\"segments\":[{\"id\":1,\"text\":\"...\"}],\"glossary\":{\"sourceTerm\":\"targetTerm\"},\"tone\":\"<formal|casual>\"}\n\nOutput:\n{\"translations\":[{\"id\":1,\"text\":\"...\",\"sourceLanguage\":\"<detected>\"}]}\n\nRules:\n1.  Use title/description for context only; do not output them.\n2.  Keep id, order, and count of segments.\n3.  Preserve whitespace, HTML entities, and all HTML-like tags (e.g., <i1>, <a1>). Translate inner text only.\n4.  Highest priority: Follow 'glossary'. Use value for translation; if value is \"\", keep the key.\n5.  Do not translate: content in <code>, <pre>, text enclosed in backticks, or placeholders like {1}, {{1}}, [1], [[1]].\n6.  Apply the specified tone to the translation.\n7.  Detect sourceLanguage for each segment.\n8.  Return empty or unchanged inputs as is.\n\nExample:\nInput: {\"targetLanguage\":\"zh-CN\",\"segments\":[{\"id\":1,\"text\":\"A <b>React</b> component.\"}],\"glossary\":{\"component\":\"组件\",\"React\":\"\"}}\nOutput: {\"translations\":[{\"id\":1,\"text\":\"一个<b>React</b>组件\",\"sourceLanguage\":\"en\"}]}\n\nFail-safe: On any error, return {\"translations\":[]}.",
      "subtitlePrompt": "You are an expert AI for subtitle generation. Convert a JSON array of word-level timestamps into a bilingual VTT file.\n\n**Workflow:**\n1. Merge `text` fields into complete sentences; ignore empty text.\n2. Split long sentences into smaller, manageable subtitle cues (one sentence per cue).\n3. Translate each cue into {{to}}.\n4. Format as VTT:\n   - Start with `WEBVTT`.\n   - Each cue: timestamps (`start --> end` in milliseconds), original text, translated text.\n   - Keep non-speech text (e.g., `[Music]`) untranslated.\n   - Separate cues with a blank line.\n\n**Output:** Only the pure VTT content.\n\n**Example:**\n```vtt\nWEBVTT\n\n1000 --> 3500\nHello world!\n你好，世界！\n\n4000 --> 6000\nGood morning.\n早上好。\n```",
      "userPrompt": "",
      "tone": "formal",
      "placeholder": "{ }",
      "placetag": [
        "i"
      ],
      "customHeader": "",
      "customBody": "",
      "reqHook": "",
      "resHook": "",
      "fetchLimit": 10,
      "fetchInterval": 100,
      "httpTimeout": 300000,
      "batchInterval": 1000,
      "batchSize": 10,
      "batchLength": 10000,
      "useBatchFetch": false,
      "useContext": false,
      "contextSize": 3,
      "temperature": 0,
      "maxTokens": 20480,
      "think": false,
      "thinkIgnore": "qwen3,deepseek-r1",
      "isDisabled": false,
      "region": ""
    },
    {
      "apiSlug": "Ollama",
      "apiName": "Ollama",
      "apiType": "Ollama",
      "url": "http://localhost:11434/v1/chat/completions",
      "key": "",
      "model": "llama3.1",
      "systemPrompt": "Act as a translation API. Output a single raw JSON object only. No extra text or fences.\n\nInput:\n{\"targetLanguage\":\"<lang>\",\"title\":\"<context>\",\"description\":\"<context>\",\"segments\":[{\"id\":1,\"text\":\"...\"}],\"glossary\":{\"sourceTerm\":\"targetTerm\"},\"tone\":\"<formal|casual>\"}\n\nOutput:\n{\"translations\":[{\"id\":1,\"text\":\"...\",\"sourceLanguage\":\"<detected>\"}]}\n\nRules:\n1.  Use title/description for context only; do not output them.\n2.  Keep id, order, and count of segments.\n3.  Preserve whitespace, HTML entities, and all HTML-like tags (e.g., <i1>, <a1>). Translate inner text only.\n4.  Highest priority: Follow 'glossary'. Use value for translation; if value is \"\", keep the key.\n5.  Do not translate: content in <code>, <pre>, text enclosed in backticks, or placeholders like {1}, {{1}}, [1], [[1]].\n6.  Apply the specified tone to the translation.\n7.  Detect sourceLanguage for each segment.\n8.  Return empty or unchanged inputs as is.\n\nExample:\nInput: {\"targetLanguage\":\"zh-CN\",\"segments\":[{\"id\":1,\"text\":\"A <b>React</b> component.\"}],\"glossary\":{\"component\":\"组件\",\"React\":\"\"}}\nOutput: {\"translations\":[{\"id\":1,\"text\":\"一个<b>React</b>组件\",\"sourceLanguage\":\"en\"}]}\n\nFail-safe: On any error, return {\"translations\":[]}.",
      "subtitlePrompt": "You are an expert AI for subtitle generation. Convert a JSON array of word-level timestamps into a bilingual VTT file.\n\n**Workflow:**\n1. Merge `text` fields into complete sentences; ignore empty text.\n2. Split long sentences into smaller, manageable subtitle cues (one sentence per cue).\n3. Translate each cue into {{to}}.\n4. Format as VTT:\n   - Start with `WEBVTT`.\n   - Each cue: timestamps (`start --> end` in milliseconds), original text, translated text.\n   - Keep non-speech text (e.g., `[Music]`) untranslated.\n   - Separate cues with a blank line.\n\n**Output:** Only the pure VTT content.\n\n**Example:**\n```vtt\nWEBVTT\n\n1000 --> 3500\nHello world!\n你好，世界！\n\n4000 --> 6000\nGood morning.\n早上好。\n```",
      "userPrompt": "",
      "tone": "formal",
      "placeholder": "{ }",
      "placetag": [
        "i"
      ],
      "customHeader": "",
      "customBody": "",
      "reqHook": "",
      "resHook": "",
      "fetchLimit": 10,
      "fetchInterval": 100,
      "httpTimeout": 300000,
      "batchInterval": 1000,
      "batchSize": 10,
      "batchLength": 10000,
      "useBatchFetch": true,
      "useContext": false,
      "contextSize": 3,
      "temperature": 0,
      "maxTokens": 20480,
      "think": false,
      "thinkIgnore": "qwen3,deepseek-r1",
      "isDisabled": false,
      "region": ""
    },
    {
      "apiSlug": "OpenRouter",
      "apiName": "OpenRouter",
      "apiType": "OpenRouter",
      "url": "https://openrouter.ai/api/v1/chat/completions",
      "key": "",
      "model": "openai/gpt-4o",
      "systemPrompt": "Act as a translation API. Output a single raw JSON object only. No extra text or fences.\n\nInput:\n{\"targetLanguage\":\"<lang>\",\"title\":\"<context>\",\"description\":\"<context>\",\"segments\":[{\"id\":1,\"text\":\"...\"}],\"glossary\":{\"sourceTerm\":\"targetTerm\"},\"tone\":\"<formal|casual>\"}\n\nOutput:\n{\"translations\":[{\"id\":1,\"text\":\"...\",\"sourceLanguage\":\"<detected>\"}]}\n\nRules:\n1.  Use title/description for context only; do not output them.\n2.  Keep id, order, and count of segments.\n3.  Preserve whitespace, HTML entities, and all HTML-like tags (e.g., <i1>, <a1>). Translate inner text only.\n4.  Highest priority: Follow 'glossary'. Use value for translation; if value is \"\", keep the key.\n5.  Do not translate: content in <code>, <pre>, text enclosed in backticks, or placeholders like {1}, {{1}}, [1], [[1]].\n6.  Apply the specified tone to the translation.\n7.  Detect sourceLanguage for each segment.\n8.  Return empty or unchanged inputs as is.\n\nExample:\nInput: {\"targetLanguage\":\"zh-CN\",\"segments\":[{\"id\":1,\"text\":\"A <b>React</b> component.\"}],\"glossary\":{\"component\":\"组件\",\"React\":\"\"}}\nOutput: {\"translations\":[{\"id\":1,\"text\":\"一个<b>React</b>组件\",\"sourceLanguage\":\"en\"}]}\n\nFail-safe: On any error, return {\"translations\":[]}.",
      "subtitlePrompt": "You are an expert AI for subtitle generation. Convert a JSON array of word-level timestamps into a bilingual VTT file.\n\n**Workflow:**\n1. Merge `text` fields into complete sentences; ignore empty text.\n2. Split long sentences into smaller, manageable subtitle cues (one sentence per cue).\n3. Translate each cue into {{to}}.\n4. Format as VTT:\n   - Start with `WEBVTT`.\n   - Each cue: timestamps (`start --> end` in milliseconds), original text, translated text.\n   - Keep non-speech text (e.g., `[Music]`) untranslated.\n   - Separate cues with a blank line.\n\n**Output:** Only the pure VTT content.\n\n**Example:**\n```vtt\nWEBVTT\n\n1000 --> 3500\nHello world!\n你好，世界！\n\n4000 --> 6000\nGood morning.\n早上好。\n```",
      "userPrompt": "",
      "tone": "formal",
      "placeholder": "{ }",
      "placetag": [
        "i"
      ],
      "customHeader": "",
      "customBody": "",
      "reqHook": "",
      "resHook": "",
      "fetchLimit": 10,
      "fetchInterval": 100,
      "httpTimeout": 300000,
      "batchInterval": 1000,
      "batchSize": 10,
      "batchLength": 10000,
      "useBatchFetch": true,
      "useContext": false,
      "contextSize": 3,
      "temperature": 0,
      "maxTokens": 20480,
      "think": false,
      "thinkIgnore": "qwen3,deepseek-r1",
      "isDisabled": false,
      "region": ""
    },
    {
      "apiSlug": "Custom",
      "apiName": "Custom",
      "apiType": "Custom",
      "url": "https://translate.googleapis.com/translate_a/single?client=gtx&dj=1&dt=t&ie=UTF-8&q={{text}}&sl=en&tl=zh-CN",
      "key": "",
      "model": "",
      "systemPrompt": "Act as a translation API. Output a single raw JSON object only. No extra text or fences.\n\nInput:\n{\"targetLanguage\":\"<lang>\",\"title\":\"<context>\",\"description\":\"<context>\",\"segments\":[{\"id\":1,\"text\":\"...\"}],\"glossary\":{\"sourceTerm\":\"targetTerm\"},\"tone\":\"<formal|casual>\"}\n\nOutput:\n{\"translations\":[{\"id\":1,\"text\":\"...\",\"sourceLanguage\":\"<detected>\"}]}\n\nRules:\n1.  Use title/description for context only; do not output them.\n2.  Keep id, order, and count of segments.\n3.  Preserve whitespace, HTML entities, and all HTML-like tags (e.g., <i1>, <a1>). Translate inner text only.\n4.  Highest priority: Follow 'glossary'. Use value for translation; if value is \"\", keep the key.\n5.  Do not translate: content in <code>, <pre>, text enclosed in backticks, or placeholders like {1}, {{1}}, [1], [[1]].\n6.  Apply the specified tone to the translation.\n7.  Detect sourceLanguage for each segment.\n8.  Return empty or unchanged inputs as is.\n\nExample:\nInput: {\"targetLanguage\":\"zh-CN\",\"segments\":[{\"id\":1,\"text\":\"A <b>React</b> component.\"}],\"glossary\":{\"component\":\"组件\",\"React\":\"\"}}\nOutput: {\"translations\":[{\"id\":1,\"text\":\"一个<b>React</b>组件\",\"sourceLanguage\":\"en\"}]}\n\nFail-safe: On any error, return {\"translations\":[]}.",
      "subtitlePrompt": "You are an expert AI for subtitle generation. Convert a JSON array of word-level timestamps into a bilingual VTT file.\n\n**Workflow:**\n1. Merge `text` fields into complete sentences; ignore empty text.\n2. Split long sentences into smaller, manageable subtitle cues (one sentence per cue).\n3. Translate each cue into {{to}}.\n4. Format as VTT:\n   - Start with `WEBVTT`.\n   - Each cue: timestamps (`start --> end` in milliseconds), original text, translated text.\n   - Keep non-speech text (e.g., `[Music]`) untranslated.\n   - Separate cues with a blank line.\n\n**Output:** Only the pure VTT content.\n\n**Example:**\n```vtt\nWEBVTT\n\n1000 --> 3500\nHello world!\n你好，世界！\n\n4000 --> 6000\nGood morning.\n早上好。\n```",
      "userPrompt": "",
      "tone": "formal",
      "placeholder": "{ }",
      "placetag": [
        "i"
      ],
      "customHeader": "",
      "customBody": "",
      "reqHook": "async (args, { url, body, headers, userMsg, method } = {}) => {\n  console.log(\"request hook args:\", args);\n  // return { url, body, headers, userMsg, method };\n}",
      "resHook": "async ({ res, ...args }) => {\n  console.log(\"reaponse hook args:\", res, args);\n  // const translations = [[\"你好\", \"zh\"]];\n  // const modelMsg = \"\";\n  // return { translations, modelMsg };\n}",
      "fetchLimit": 10,
      "fetchInterval": 100,
      "httpTimeout": 300000,
      "batchInterval": 1000,
      "batchSize": 10,
      "batchLength": 10000,
      "useBatchFetch": false,
      "useContext": false,
      "contextSize": 3,
      "temperature": 0,
      "maxTokens": 20480,
      "think": false,
      "thinkIgnore": "qwen3,deepseek-r1",
      "isDisabled": false,
      "region": ""
    }
  ],
  "shortcuts": {
    "toggleTranslate": [
      "AltLeft",
      "KeyQ"
    ],
    "toggleStyle": [
      "AltLeft",
      "KeyC"
    ],
    "togglePopup": [
      "AltLeft",
      "KeyK"
    ],
    "openSetting": [
      "AltLeft",
      "KeyO"
    ]
  },
  "inputRule": {
    "transOpen": false,
    "apiSlug": "Google2",
    "fromLang": "auto",
    "toLang": "en",
    "triggerShortcut": [
      "AltLeft",
      "KeyI"
    ],
    "triggerCount": 1,
    "triggerTime": 200,
    "transSign": "/"
  },
  "tranboxSetting": {
    "transOpen": false,
    "apiSlugs": [
      "Google2"
    ],
    "fromLang": "auto",
    "toLang": "zh-CN",
    "toLang2": "en",
    "tranboxShortcut": [
      "AltLeft",
      "KeyS"
    ],
    "btnOffsetX": 10,
    "btnOffsetY": 10,
    "boxOffsetX": 0,
    "boxOffsetY": 10,
    "hideTranBtn": false,
    "hideClickAway": true,
    "simpleStyle": true,
    "followSelection": true,
    "triggerMode": "select",
    "enDict": "Bing",
    "enSug": "Youdao"
  },
  "touchTranslate": 2,
  "blacklist": "https://fishjar.github.io/kiss-translator/options.html,\nhttps://translate.google.com,\nhttps://www.deepl.com/translator",
  "csplist": "",
  "orilist": "https://dict.youdao.com",
  "skipLangs": [],
  "transInterval": 100,
  "langDetector": "-",
  "mouseHoverSetting": {
    "useMouseHover": false,
    "mouseHoverKey": [
      "KeyQ"
    ]
  },
  "preInit": true,
  "transAllnow": false,
  "subtitleSetting": {
    "enabled": true,
    "apiSlug": "Google2",
    "segSlug": "-",
    "chunkLength": 1000,
    "toLang": "zh-CN",
    "isBilingual": true,
    "windowStyle": "padding: 0.5em 1em;\nbackground-color: rgba(0, 0, 0, 0.5);\ncolor: white;\nline-height: 1.3;\ntext-shadow: 1px 1px 2px black;\ndisplay: inline-block",
    "originStyle": "font-size: clamp(1.5rem, 3cqw, 3rem);",
    "translationStyle": "font-size: clamp(1.5rem, 3cqw, 3rem);"
  },
  "logLevel": 1
}